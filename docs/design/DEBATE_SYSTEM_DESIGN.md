# í† ë¡  ì‹œìŠ¤í…œ ì„¤ê³„
**Multi-Agent Debate Protocol for Image Forensics**

---

## ğŸ¯ í† ë¡ ì˜ ëª©ì 

í˜„ì¬ ë¬¸ì œ:
```
FrequencyAgent: AI_GENERATED (0.85)
NoiseAgent: AUTHENTIC (0.70)

â†’ ë‹¨ìˆœ íˆ¬í‘œ: AI_GENERATED wins (ì‹ ë¢°ë„ ë†’ìŒ)
â†’ ë¬¸ì œ: NoiseAgentì˜ ì˜ê²¬ì´ ë¬µì‚´ë¨
```

í† ë¡  í›„:
```
FrequencyAgent: "ê²©ì íŒ¨í„´ ë°œê²¬"
NoiseAgent: "í•˜ì§€ë§Œ PRNU ìˆìŒ â†’ ì‹¤ì œ ì‚¬ì§„ì— AI ê°ì²´ ì¶”ê°€í•œ ê²ƒ"

â†’ Manager: "í˜¼í•© ì´ë¯¸ì§€ë¡œ íŒì •. ì¡°ì‘ë¨ (MANIPULATED)"
â†’ SpatialAgentì—ê²Œ ì¡°ì‘ ì˜ì—­ ì°¾ë„ë¡ ìš”ì²­
```

---

## ğŸ“‹ í† ë¡  í”„ë¡œí† ì½œ

### Phase 1: ì´ˆê¸° ë¶„ì„
```
ëª¨ë“  Agent â†’ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„ â†’ íŒì • ì œì¶œ
```

**ì¶œë ¥**:
```python
{
    "frequency": AgentResponse(verdict=AI_GENERATED, confidence=0.85),
    "noise": AgentResponse(verdict=AUTHENTIC, confidence=0.70),
    "watermark": AgentResponse(verdict=UNCERTAIN, confidence=0.50),
    "spatial": AgentResponse(verdict=AI_GENERATED, confidence=0.78)
}
```

### Phase 2: ë¶ˆì¼ì¹˜ íƒì§€
```python
def detect_disagreement(responses: Dict[str, AgentResponse]) -> float:
    """ë¶ˆì¼ì¹˜ ìˆ˜ì¤€ ê³„ì‚°"""
    verdicts = [r.verdict for r in responses.values()]
    unique_verdicts = len(set(verdicts))

    # ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ë¶ˆì¼ì¹˜ ì¸¡ì •
    disagreement_level = unique_verdicts / len(verdicts)

    return disagreement_level
```

**íŒë‹¨ ê¸°ì¤€**:
- `disagreement_level > 0.5` â†’ í† ë¡  í•„ìš”
- `disagreement_level â‰¤ 0.5` â†’ í•©ì˜ë¨, í† ë¡  ë¶ˆí•„ìš”

### Phase 3: í† ë¡  ë¼ìš´ë“œ

#### ë¼ìš´ë“œ êµ¬ì¡°
```
Round 1:
  FrequencyAgent â†’ NoiseAgent: "ì™œ AUTHENTICì¸ê°€?"
  NoiseAgent â†’ FrequencyAgent: "PRNU ìˆê¸° ë•Œë¬¸"

Round 2:
  FrequencyAgent â†’ NoiseAgent: "PRNU ì¼ê´€ì„±ì´ ë‚®ì€ë°?"
  NoiseAgent â†’ FrequencyAgent: "í˜¼í•© ì´ë¯¸ì§€ ê°€ëŠ¥ì„±"

Round 3:
  Managerê°€ ê°œì…: "ì–‘ì¸¡ ì˜ê²¬ ëª¨ë‘ íƒ€ë‹¹. MANIPULATEDë¡œ íŒì •"
```

---

## ğŸ”§ êµ¬í˜„ êµ¬ì¡°

### 1. DebateProtocol í´ë˜ìŠ¤

```python
# src/debate/debate_protocol.py

from typing import Dict, List, Tuple
from dataclasses import dataclass
from ..agents.base_agent import AgentResponse
from ..tools.base_tool import Verdict


@dataclass
class DebateTurn:
    """í† ë¡ ì˜ í•œ í„´"""
    round_number: int
    challenger: str  # Agent ì´ë¦„
    challenged: str
    challenge: str  # ë„ì „ ë‚´ìš©
    response: str  # ì‘ë‹µ ë‚´ìš©
    verdict_before: Verdict  # ì‘ë‹µ ì „ íŒì •
    verdict_after: Verdict  # ì‘ë‹µ í›„ íŒì • (ë³€ê²½ ê°€ëŠ¥)
    confidence_change: float  # ì‹ ë¢°ë„ ë³€í™”


@dataclass
class DebateResult:
    """í† ë¡  ê²°ê³¼"""
    total_rounds: int
    turns: List[DebateTurn]
    final_verdicts: Dict[str, Verdict]
    consensus_reached: bool
    disagreement_level_before: float
    disagreement_level_after: float


class DebateProtocol:
    """í† ë¡  í”„ë¡œí† ì½œ ê´€ë¦¬ì"""

    def __init__(self, max_rounds: int = 3):
        self.max_rounds = max_rounds

    def should_debate(self, responses: Dict[str, AgentResponse]) -> bool:
        """í† ë¡  í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        disagreement = self._compute_disagreement(responses)
        return disagreement > 0.5

    def _compute_disagreement(self, responses: Dict[str, AgentResponse]) -> float:
        """ë¶ˆì¼ì¹˜ ìˆ˜ì¤€ ê³„ì‚°"""
        verdicts = [r.verdict for r in responses.values()]
        unique_verdicts = len(set(verdicts))
        return unique_verdicts / len(verdicts) if verdicts else 0.0

    def conduct_debate(
        self,
        agents: Dict[str, 'BaseAgent'],
        responses: Dict[str, AgentResponse]
    ) -> DebateResult:
        """í† ë¡  ì§„í–‰"""

        turns = []
        current_round = 1

        # í† ë¡  ëŒ€ìƒ ìŒ ì°¾ê¸°
        debate_pairs = self._find_debate_pairs(responses)

        while current_round <= self.max_rounds:
            round_turns = []

            for agent_a, agent_b in debate_pairs:
                # Aê°€ Bì—ê²Œ ë„ì „
                turn = self._execute_challenge(
                    challenger=agents[agent_a],
                    challenged=agents[agent_b],
                    round_number=current_round,
                    all_responses=responses
                )
                round_turns.append(turn)

                # íŒì • ë³€ê²½ í™•ì¸
                if turn.verdict_after != turn.verdict_before:
                    # íŒì •ì´ ë°”ë€Œë©´ responses ì—…ë°ì´íŠ¸
                    responses[agent_b].verdict = turn.verdict_after
                    responses[agent_b].confidence += turn.confidence_change

            turns.extend(round_turns)

            # í•©ì˜ í™•ì¸
            if self._check_consensus(responses):
                break

            current_round += 1

        return DebateResult(
            total_rounds=current_round - 1,
            turns=turns,
            final_verdicts={name: r.verdict for name, r in responses.items()},
            consensus_reached=self._check_consensus(responses),
            disagreement_level_before=self._compute_disagreement(responses),
            disagreement_level_after=self._compute_disagreement(responses)
        )

    def _find_debate_pairs(
        self,
        responses: Dict[str, AgentResponse]
    ) -> List[Tuple[str, str]]:
        """í† ë¡ í•  Agent ìŒ ì°¾ê¸°"""
        pairs = []
        agent_names = list(responses.keys())

        for i, name_a in enumerate(agent_names):
            for name_b in agent_names[i+1:]:
                # íŒì •ì´ ë‹¤ë¥´ë©´ í† ë¡  ëŒ€ìƒ
                if responses[name_a].verdict != responses[name_b].verdict:
                    # ì‹ ë¢°ë„ ë†’ì€ ìª½ì´ ë„ì „ì
                    if responses[name_a].confidence > responses[name_b].confidence:
                        pairs.append((name_a, name_b))
                    else:
                        pairs.append((name_b, name_a))

        return pairs

    def _execute_challenge(
        self,
        challenger: 'BaseAgent',
        challenged: 'BaseAgent',
        round_number: int,
        all_responses: Dict[str, AgentResponse]
    ) -> DebateTurn:
        """í•œ í„´ì˜ ë„ì „-ì‘ë‹µ ì‹¤í–‰"""

        # ë„ì „ìì˜ ì£¼ì¥
        challenge = challenger.generate_challenge(
            my_verdict=all_responses[challenger.name].verdict,
            my_evidence=all_responses[challenger.name].evidence,
            opponent_verdict=all_responses[challenged.name].verdict,
            opponent_evidence=all_responses[challenged.name].evidence
        )

        # í”¼ë„ì „ìì˜ ì‘ë‹µ
        response_result = challenged.respond_to_challenge(
            challenge=challenge,
            challenger_name=challenger.name,
            my_current_verdict=all_responses[challenged.name].verdict,
            my_evidence=all_responses[challenged.name].evidence
        )

        return DebateTurn(
            round_number=round_number,
            challenger=challenger.name,
            challenged=challenged.name,
            challenge=challenge,
            response=response_result['response'],
            verdict_before=all_responses[challenged.name].verdict,
            verdict_after=response_result.get('verdict_after', all_responses[challenged.name].verdict),
            confidence_change=response_result.get('confidence_change', 0.0)
        )

    def _check_consensus(self, responses: Dict[str, AgentResponse]) -> bool:
        """í•©ì˜ ë„ë‹¬ ì—¬ë¶€ í™•ì¸"""
        verdicts = [r.verdict for r in responses.values()]
        # ëª¨ë“  íŒì •ì´ ê°™ê±°ë‚˜, ë¶ˆì¼ì¹˜ê°€ ë§¤ìš° ë‚®ìŒ
        return len(set(verdicts)) <= 1 or self._compute_disagreement(responses) < 0.3
```

---

## ğŸ’¬ Agentì˜ í† ë¡  ë©”ì„œë“œ

### BaseAgentì— ì¶”ê°€í•  ë©”ì„œë“œ

```python
# src/agents/base_agent.py

class BaseAgent(ABC):
    """ê¸°ë³¸ Agent í´ë˜ìŠ¤"""

    # ê¸°ì¡´ ë©”ì„œë“œë“¤...

    def generate_challenge(
        self,
        my_verdict: Verdict,
        my_evidence: Dict,
        opponent_verdict: Verdict,
        opponent_evidence: Dict
    ) -> str:
        """
        ë‹¤ë¥¸ Agentì—ê²Œ ë„ì „

        "ë‚˜ëŠ” Xë¼ê³  íŒë‹¨í–ˆëŠ”ë°, ë„ˆëŠ” ì™œ Yë¼ê³  í•˜ëŠ”ê°€?"
        """
        if not hasattr(self, '_llm') or self._llm is None:
            # LLM ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜
            return self._generate_rule_based_challenge(
                my_verdict, opponent_verdict
            )

        # LLM ê¸°ë°˜ ë„ì „
        prompt = f"""ë‹¹ì‹ ì€ {self.name}ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ë¶„ì„:
- íŒì •: {my_verdict.value}
- ì¦ê±°: {json.dumps(my_evidence, indent=2)}

ë‹¤ë¥¸ ì „ë¬¸ê°€ì˜ ë¶„ì„:
- íŒì •: {opponent_verdict.value}
- ì¦ê±°: {json.dumps(opponent_evidence, indent=2)}

ë‹¹ì‹ ì˜ ë¶„ì„ê³¼ ë‹¤ë¥¸ ì „ë¬¸ê°€ì˜ ë¶„ì„ì´ ìƒì¶©í•©ë‹ˆë‹¤.
ì „ë¬¸ê°€ë¡œì„œ, ìƒëŒ€ë°©ì˜ íŒì •ì— ë…¼ë¦¬ì ìœ¼ë¡œ ë„ì „í•˜ì„¸ìš”.

í˜•ì‹:
"ë‹¹ì‹ ì€ {opponent_verdict.value}ë¡œ íŒë‹¨í–ˆì§€ë§Œ, ì €ëŠ” [í•µì‹¬ ì¦ê±°]ë¥¼ ê·¼ê±°ë¡œ {my_verdict.value}ë¼ê³  ë´…ë‹ˆë‹¤. [êµ¬ì²´ì  ë…¼ê±°]"
"""

        return self._llm.generate(prompt)

    def respond_to_challenge(
        self,
        challenge: str,
        challenger_name: str,
        my_current_verdict: Verdict,
        my_evidence: Dict
    ) -> Dict:
        """
        ë„ì „ì— ì‘ë‹µ

        Returns:
            {
                "response": str,  # ì‘ë‹µ ë‚´ìš©
                "verdict_after": Verdict,  # ì‘ë‹µ í›„ íŒì • (ë³€ê²½ ê°€ëŠ¥)
                "confidence_change": float  # ì‹ ë¢°ë„ ë³€í™”
            }
        """
        if not hasattr(self, '_llm') or self._llm is None:
            return self._generate_rule_based_response(challenge)

        # ë„ë©”ì¸ ì§€ì‹ ë¡œë“œ
        domain_knowledge = self._get_domain_knowledge_summary()

        prompt = f"""ë‹¹ì‹ ì€ {self.name}ì…ë‹ˆë‹¤.

# ë„ë©”ì¸ ì§€ì‹
{domain_knowledge}

# ë‹¹ì‹ ì˜ í˜„ì¬ íŒì •
- íŒì •: {my_current_verdict.value}
- ì¦ê±°: {json.dumps(my_evidence, indent=2)}

# ë‹¤ë¥¸ ì „ë¬¸ê°€ì˜ ë„ì „
{challenger_name}: "{challenge}"

# ìš”ì²­
1. ìƒëŒ€ë°©ì˜ ì£¼ì¥ì„ ë¶„ì„í•˜ì„¸ìš”
2. ë‹¹ì‹ ì˜ ì¦ê±°ë¡œ ë…¼ë¦¬ì ìœ¼ë¡œ ë°˜ë°•í•˜ì„¸ìš”
3. ìƒëŒ€ë°©ì˜ ì£¼ì¥ì´ íƒ€ë‹¹í•˜ë‹¤ë©´, íŒì •ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
4. íŒì •ì„ ë°”ê¾¸ì§€ ì•ŠëŠ”ë‹¤ë©´, ëª…í™•í•œ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”

# ì¶œë ¥ í˜•ì‹ (JSON)
{{
    "response": "ë‹¹ì‹ ì˜ ë°˜ë°• ë˜ëŠ” ì¸ì •",
    "verdict_changed": true/false,
    "new_verdict": "AI_GENERATED/AUTHENTIC/MANIPULATED/UNCERTAIN" (ë³€ê²½ ì‹œ),
    "confidence_change": -0.1 ~ +0.1,
    "reasoning": "íŒì • ë³€ê²½ ë˜ëŠ” ìœ ì§€ ì´ìœ "
}}
"""

        llm_output = self._llm.generate(prompt)

        try:
            result = json.loads(llm_output)
            return {
                "response": result.get("response", ""),
                "verdict_after": Verdict(result["new_verdict"]) if result.get("verdict_changed") else my_current_verdict,
                "confidence_change": result.get("confidence_change", 0.0)
            }
        except (json.JSONDecodeError, KeyError):
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë³€ê²½ ì—†ìŒ
            return {
                "response": llm_output,
                "verdict_after": my_current_verdict,
                "confidence_change": 0.0
            }

    def _generate_rule_based_challenge(
        self,
        my_verdict: Verdict,
        opponent_verdict: Verdict
    ) -> str:
        """ê·œì¹™ ê¸°ë°˜ ë„ì „ (LLM ì—†ì„ ë•Œ)"""
        return f"ì œ ë¶„ì„ ê²°ê³¼ëŠ” {my_verdict.value}ì…ë‹ˆë‹¤. {opponent_verdict.value}ë¡œ íŒë‹¨í•œ ê·¼ê±°ê°€ ë¬´ì—‡ì…ë‹ˆê¹Œ?"

    def _generate_rule_based_response(self, challenge: str) -> Dict:
        """ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ (LLM ì—†ì„ ë•Œ)"""
        return {
            "response": "ì œ ë¶„ì„ ë„êµ¬ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤.",
            "verdict_after": None,  # ë³€ê²½ ì—†ìŒ
            "confidence_change": 0.0
        }

    def _get_domain_knowledge_summary(self) -> str:
        """ë„ë©”ì¸ ì§€ì‹ ìš”ì•½ (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        return ""
```

---

## ğŸ­ í† ë¡  ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì‹œ

### Scenario 1: í•©ì˜ ë„ë‹¬

```
[ì´ˆê¸° ìƒíƒœ]
Frequency: AI_GENERATED (0.85) - "ê²©ì íŒ¨í„´ ëª…í™•"
Noise: AUTHENTIC (0.70) - "PRNU ê²€ì¶œ"
Spatial: AI_GENERATED (0.78) - "í…ìŠ¤ì²˜ ë¶ˆì¼ì¹˜"

[Round 1]
Frequency â†’ Noise:
  "ê²©ì íŒ¨í„´ì´ 0.78ë¡œ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ì™œ AUTHENTICë¼ê³  íŒë‹¨í•˜ì…¨ìŠµë‹ˆê¹Œ?"

Noise â†’ Frequency:
  "PRNU íŒ¨í„´ì´ ê²€ì¶œë˜ì—ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ...
   PRNU ì¼ê´€ì„±ì´ 0.65ë¡œ ì¤‘ê°„ ìˆ˜ì¤€ì´ë„¤ìš”.
   ì‹¤ì œ ì‚¬ì§„ì— AI ê°ì²´ê°€ ì¶”ê°€ëœ í˜¼í•© ì´ë¯¸ì§€ì¼ ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤."
  â†’ íŒì • ë³€ê²½: AUTHENTIC â†’ MANIPULATED
  â†’ ì‹ ë¢°ë„ ì¡°ì •: 0.70 â†’ 0.75

[Round 2]
Spatial â†’ Noise:
  "í…ìŠ¤ì²˜ ë¶ˆì¼ì¹˜ë¥¼ ë°œê²¬í–ˆê³ , íŠ¹ì • ì˜ì—­ì´ ì˜ì‹¬ë©ë‹ˆë‹¤.
   MANIPULATED íŒì •ì— ë™ì˜í•©ë‹ˆë‹¤."

Frequency â†’ (ëª¨ë‘):
  "ê²©ì íŒ¨í„´ì€ ì¶”ê°€ëœ ê°ì²´ì—ì„œ ë°œê²¬ëì„ ê²ƒì…ë‹ˆë‹¤.
   MANIPULATEDì— ë™ì˜í•©ë‹ˆë‹¤."
  â†’ íŒì • ë³€ê²½: AI_GENERATED â†’ MANIPULATED

[ìµœì¢… í•©ì˜]
ëª¨ë‘ MANIPULATED â†’ í† ë¡  ì¢…ë£Œ
Manager: "ë§Œì¥ì¼ì¹˜ë¡œ MANIPULATED íŒì •"
```

### Scenario 2: í•©ì˜ ì‹¤íŒ¨

```
[ì´ˆê¸° ìƒíƒœ]
Frequency: AI_GENERATED (0.92) - "ëª…í™•í•œ ê²©ì íŒ¨í„´"
Noise: AUTHENTIC (0.88) - "ê°•í•œ PRNU"

[Round 1-3]
- ì–‘ì¸¡ ëª¨ë‘ ê°•í•œ ì¦ê±°
- íŒì • ë³€ê²½ ì—†ìŒ

[Manager ê°œì…]
"ì–‘ì¸¡ ì¦ê±° ëª¨ë‘ íƒ€ë‹¹í•©ë‹ˆë‹¤.
 ì´ëŠ” ê³ ê¸‰ í•©ì„± ê¸°ë²•ì´ ì‚¬ìš©ëœ MANIPULATED ì´ë¯¸ì§€ë¡œ íŒì •í•©ë‹ˆë‹¤.
 - ë°°ê²½: ì‹¤ì œ ì‚¬ì§„ (PRNU ìˆìŒ)
 - ê°ì²´: AI ìƒì„± (ê²©ì íŒ¨í„´ ìˆìŒ)"
```

---

## ğŸ“Š í† ë¡  íš¨ê³¼

### Before (í† ë¡  ì—†ìŒ)
```
ê²°ê³¼: AI_GENERATED (í‰ê·  ì‹ ë¢°ë„ 0.75)
ê·¼ê±°: "ì—¬ëŸ¬ ë¶„ì„ ê²°ê³¼ ì¢…í•©"
```

### After (í† ë¡  ìˆìŒ)
```
ê²°ê³¼: MANIPULATED (ì‹ ë¢°ë„ 0.82)
ê·¼ê±°:
"ì´ˆê¸°ì—ëŠ” Frequency Agentê°€ AI_GENERATEDë¡œ íŒë‹¨í–ˆìœ¼ë‚˜,
 Noise Agentê°€ PRNU ì¡´ì¬ë¥¼ ì§€ì í–ˆìŠµë‹ˆë‹¤.
 í† ë¡  ê²°ê³¼, ì‹¤ì œ ì‚¬ì§„ì— AIë¡œ ìƒì„±í•œ ê°ì²´ë¥¼ í•©ì„±í•œ
 í˜¼í•© ì´ë¯¸ì§€ë¡œ íŒì •í–ˆìŠµë‹ˆë‹¤.

 Spatial Agentê°€ (200, 150) ì˜ì—­ì—ì„œ ì¡°ì‘ í”ì ì„ ë°œê²¬í•˜ì—¬
 ì´ë¥¼ ë’·ë°›ì¹¨í•©ë‹ˆë‹¤."
```

---

## ğŸ”„ ManagerAgent í†µí•©

```python
# src/agents/manager_agent.py

class ManagerAgent(BaseAgent):

    def __init__(self, ...):
        # ê¸°ì¡´ ì½”ë“œ...
        self.debate_protocol = DebateProtocol(max_rounds=3)

    def analyze(self, image, context=None):
        # 1. ê°œë³„ ë¶„ì„
        responses = self._collect_analyses(image, context)

        # 2. í† ë¡  í•„ìš” ì—¬ë¶€
        if self.debate_protocol.should_debate(responses):
            # 3. í† ë¡  ì§„í–‰
            debate_result = self.debate_protocol.conduct_debate(
                agents=self.agents,
                responses=responses
            )

            # 4. í† ë¡  ê²°ê³¼ ë°˜ì˜
            responses = {
                name: resp for name, resp in responses.items()
            }  # í† ë¡ ìœ¼ë¡œ ì—…ë°ì´íŠ¸ëœ responses

            # 5. ìµœì¢… íŒì •
            final_verdict = self._make_final_decision_with_debate(
                responses, debate_result
            )
        else:
            # í† ë¡  ë¶ˆí•„ìš”
            final_verdict = self._make_final_decision(responses)

        return final_verdict
```

---

## âœ… êµ¬í˜„ ìˆœì„œ

```
1. DebateProtocol í´ë˜ìŠ¤ ì‘ì„±
   â””â”€ src/debate/debate_protocol.py

2. BaseAgentì— í† ë¡  ë©”ì„œë“œ ì¶”ê°€
   â””â”€ generate_challenge()
   â””â”€ respond_to_challenge()

3. ê° Specialist Agentì— LLM í†µí•©
   â””â”€ FrequencyAgent, NoiseAgent, WatermarkAgent, SpatialAgent
   â””â”€ Knowledge Base ë¡œë“œ

4. ManagerAgentì— í† ë¡  ì‹œìŠ¤í…œ í†µí•©
   â””â”€ DebateProtocol ì‚¬ìš©

5. í…ŒìŠ¤íŠ¸ ì‘ì„±
   â””â”€ tests/test_debate_system.py
```

---

ì´ ì„¤ê³„ë¡œ êµ¬í˜„ì„ ì§„í–‰í• ê¹Œìš”?
